{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0B6zZ_jOMhc",
        "outputId": "3cd4be69-24b1-4060-efa1-c6497fb31b86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Build a Classification Model with Spark with a dataset of your choice"
      ],
      "metadata": {
        "id": "o0ww21ygPJkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Iris Classification\") \\\n",
        "    .getOrCreate()\n",
        "import urllib.request\n",
        "\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\"\n",
        "urllib.request.urlretrieve(url, \"iris.csv\")\n",
        "df = spark.read.csv(\"iris.csv\", header=True, inferSchema=True)\n",
        "\n",
        "df.show(5)\n",
        "\n",
        "indexer = StringIndexer(inputCol=\"species\", outputCol=\"label\")\n",
        "df_indexed = indexer.fit(df).transform(df)\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "df_final = assembler.transform(df_indexed).select(\"features\", \"label\")\n",
        "\n",
        "train_data, test_data = df_final.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
        "lr_model = lr.fit(train_data)\n",
        "\n",
        "predictions = lr_model.transform(test_data)\n",
        "predictions.select(\"features\", \"label\", \"prediction\").show()\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVJVRDmBOPGP",
        "outputId": "0025937c-215c-42ec-ed49-f088a075f302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+------------+-----------+-------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
            "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
            "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
            "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
            "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------------+-----+----------+\n",
            "|         features|label|prediction|\n",
            "+-----------------+-----+----------+\n",
            "|[4.4,3.0,1.3,0.2]|  0.0|       0.0|\n",
            "|[4.6,3.2,1.4,0.2]|  0.0|       0.0|\n",
            "|[4.6,3.6,1.0,0.2]|  0.0|       0.0|\n",
            "|[4.8,3.1,1.6,0.2]|  0.0|       0.0|\n",
            "|[4.9,3.1,1.5,0.1]|  0.0|       0.0|\n",
            "|[5.0,2.3,3.3,1.0]|  1.0|       1.0|\n",
            "|[5.0,3.5,1.3,0.3]|  0.0|       0.0|\n",
            "|[5.1,3.5,1.4,0.2]|  0.0|       0.0|\n",
            "|[5.3,3.7,1.5,0.2]|  0.0|       0.0|\n",
            "|[5.4,3.0,4.5,1.5]|  1.0|       1.0|\n",
            "|[5.4,3.4,1.5,0.4]|  0.0|       0.0|\n",
            "|[5.4,3.7,1.5,0.2]|  0.0|       0.0|\n",
            "|[5.4,3.9,1.7,0.4]|  0.0|       0.0|\n",
            "|[5.5,2.5,4.0,1.3]|  1.0|       1.0|\n",
            "|[5.6,2.9,3.6,1.3]|  1.0|       1.0|\n",
            "|[5.7,2.9,4.2,1.3]|  1.0|       1.0|\n",
            "|[5.8,2.7,5.1,1.9]|  2.0|       2.0|\n",
            "|[6.3,2.5,4.9,1.5]|  1.0|       1.0|\n",
            "|[6.4,3.1,5.5,1.8]|  2.0|       2.0|\n",
            "|[6.5,3.0,5.2,2.0]|  2.0|       2.0|\n",
            "+-----------------+-----+----------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Build  a Clustering Model with Spark with a dataset of your choice\n"
      ],
      "metadata": {
        "id": "L9N7RVQTPT2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.evaluation import ClusteringEvaluator\n",
        "import urllib.request\n",
        "\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Iris Clustering\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\"\n",
        "urllib.request.urlretrieve(url, \"iris.csv\")\n",
        "\n",
        "\n",
        "df = spark.read.csv(\"iris.csv\", header=True, inferSchema=True)\n",
        "df.show(5)\n",
        "\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "df_features = assembler.transform(df).select(\"features\")\n",
        "df_features.show(5)\n",
        "\n",
        "kmeans = KMeans().setK(3).setSeed(1)\n",
        "model = kmeans.fit(df_features)\n",
        "\n",
        "predictions = model.transform(df_features)\n",
        "predictions.show(5)\n",
        "\n",
        "evaluator = ClusteringEvaluator()\n",
        "\n",
        "silhouette = evaluator.evaluate(predictions)\n",
        "print(f\"Silhouette Score = {silhouette:.2f}\")\n",
        "\n",
        "centers = model.clusterCenters()\n",
        "print(\"Cluster Centers:\")\n",
        "for center in centers:\n",
        "    print(center)\n",
        "\n",
        "\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TRFptaYPdii",
        "outputId": "3af47eb0-f912-4d37-cb9f-b28a622cf50e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+------------+-----------+-------+\n",
            "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
            "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
            "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
            "|         4.6|        3.1|         1.5|        0.2| setosa|\n",
            "|         5.0|        3.6|         1.4|        0.2| setosa|\n",
            "+------------+-----------+------------+-----------+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------------+\n",
            "|         features|\n",
            "+-----------------+\n",
            "|[5.1,3.5,1.4,0.2]|\n",
            "|[4.9,3.0,1.4,0.2]|\n",
            "|[4.7,3.2,1.3,0.2]|\n",
            "|[4.6,3.1,1.5,0.2]|\n",
            "|[5.0,3.6,1.4,0.2]|\n",
            "+-----------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+-----------------+----------+\n",
            "|         features|prediction|\n",
            "+-----------------+----------+\n",
            "|[5.1,3.5,1.4,0.2]|         1|\n",
            "|[4.9,3.0,1.4,0.2]|         1|\n",
            "|[4.7,3.2,1.3,0.2]|         1|\n",
            "|[4.6,3.1,1.5,0.2]|         1|\n",
            "|[5.0,3.6,1.4,0.2]|         1|\n",
            "+-----------------+----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Silhouette Score = 0.74\n",
            "Cluster Centers:\n",
            "[5.9016129  2.7483871  4.39354839 1.43387097]\n",
            "[5.006 3.418 1.464 0.244]\n",
            "[6.85       3.07368421 5.74210526 2.07105263]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Build a Recommendation Engine with Spark with a dataset of your choice"
      ],
      "metadata": {
        "id": "ubvpnp1dP7Or"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql.functions import col\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Movie Recommendation Engine\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "url = \"http://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
        "urllib.request.urlretrieve(url, \"ml-100k.zip\")\n",
        "\n",
        "with zipfile.ZipFile(\"ml-100k.zip\", \"r\") as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "\n",
        "ratings_path = \"ml-100k/u.data\"\n",
        "ratings_df = spark.read.csv(ratings_path, sep=\"\\t\", inferSchema=True)\\\n",
        "    .toDF(\"userId\", \"movieId\", \"rating\", \"timestamp\")\n",
        "\n",
        "ratings_df.show(5)\n",
        "\n",
        "(training, test) = ratings_df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "als = ALS(\n",
        "    userCol=\"userId\",\n",
        "    itemCol=\"movieId\",\n",
        "    ratingCol=\"rating\",\n",
        "    coldStartStrategy=\"drop\"\n",
        ")\n",
        "model = als.fit(training)\n",
        "\n",
        "predictions = model.transform(test)\n",
        "\n",
        "evaluator = RegressionEvaluator(\n",
        "    metricName=\"rmse\",\n",
        "    labelCol=\"rating\",\n",
        "    predictionCol=\"prediction\"\n",
        ")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Root-mean-square error = {rmse:.2f}\")\n",
        "\n",
        "userRecs = model.recommendForAllUsers(5)\n",
        "userRecs.show(5, truncate=False)\n",
        "\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXmWEqu2QDA3",
        "outputId": "046e34f9-9b0e-4401-e5d3-9f187e740f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------+------+---------+\n",
            "|userId|movieId|rating|timestamp|\n",
            "+------+-------+------+---------+\n",
            "|   196|    242|     3|881250949|\n",
            "|   186|    302|     3|891717742|\n",
            "|    22|    377|     1|878887116|\n",
            "|   244|     51|     2|880606923|\n",
            "|   166|    346|     1|886397596|\n",
            "+------+-------+------+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Root-mean-square error = 0.92\n",
            "+------+------------------------------------------------------------------------------------------+\n",
            "|userId|recommendations                                                                           |\n",
            "+------+------------------------------------------------------------------------------------------+\n",
            "|1     |[{169, 5.145367}, {1449, 5.1151657}, {408, 5.0260806}, {114, 4.9943943}, {1129, 4.939193}]|\n",
            "|2     |[{1449, 5.1401997}, {119, 4.7666917}, {169, 4.6891603}, {318, 4.6781487}, {64, 4.676061}] |\n",
            "|3     |[{1643, 5.0305285}, {1368, 4.4396415}, {320, 4.178387}, {74, 4.1180644}, {865, 4.080035}] |\n",
            "|4     |[{1631, 5.883494}, {1449, 5.8274236}, {1368, 5.769343}, {320, 5.7080526}, {867, 5.69582}] |\n",
            "|5     |[{954, 4.4914966}, {1022, 4.360721}, {1656, 4.356598}, {850, 4.2906313}, {169, 4.269669}] |\n",
            "+------+------------------------------------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    }
  ]
}